{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb2af2ac",
   "metadata": {},
   "source": [
    "# SVM Model for Tumour Classification\n",
    "## A. Binary Task\n",
    "### Build a classifier to identify whether there is a tumor in the MRI images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc538f",
   "metadata": {},
   "source": [
    "Import necessary libraries, matplotlib, pandas, numpy, sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc4cded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31d397d",
   "metadata": {},
   "source": [
    "Read label.csv; Define image data folder path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ebfd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_array = pd.read_csv('./dataset/label.csv')\n",
    "\n",
    "dir_image = \"./dataset/image/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10a76b",
   "metadata": {},
   "source": [
    "PCA dimension reduction step 1: \n",
    "Find the number of principle components needed to keep all image data variance more than 99% after dimension reduction. Result is 102 dimension needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843ea412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "pca_num:  102.0\n"
     ]
    }
   ],
   "source": [
    "rows = 3000                           #rows is number of images\n",
    "     \n",
    "pca_targets = np.zeros(rows)          #pca_targets is used to store number of principle components needed for each image\n",
    "print(pca_targets.shape)\n",
    "\n",
    "# read in every image; \n",
    "# reduce it from RGB to grey scale (reduce data size by removing unnecessary data);\n",
    "# for each image, use PCA to find the number of principle components needed to reserve\n",
    "#     more than 99% data variance; The largest number found among all images is the \n",
    "#     final number of principle components needed (for all images to keep 99% data \n",
    "#     variance after dimension reduction).\n",
    "for i in range(rows):  \n",
    "    #Read in each image\n",
    "    img = mpimg.imread(dir_image + csv_array.file_name[i])[...,0]\n",
    "    \n",
    "    #Implement PCA with full features of image (512)\n",
    "    pca_512 = PCA(n_components = 512, random_state = 2020) \n",
    "    pca_512.fit(img)\n",
    "    \n",
    "    #Get the cumulative explained_variance_ratio_\n",
    "    a = np.cumsum(pca_512.explained_variance_ratio_ * 100)\n",
    "    \n",
    "    #Set necessary explained_variance_ratio_ to 99%\n",
    "    #Get number of principle components needed to obtain expected explained_variance_ratio_\n",
    "    threshold = 99\n",
    "    matched_index = np.where(a > threshold)[0][0]\n",
    "    pca_targets[i] = matched_index\n",
    "    \n",
    "    if i%500 == 0:     #print index to indicate processing progress\n",
    "        print(i)\n",
    "        \n",
    "#Find the largest dimention number to keep all images' explained_variance_ratio_ more than 99%\n",
    "pca_num = np.amax(pca_targets)\n",
    "print(\"pca_num: \", pca_num)\n",
    "\n",
    "#This part of code is to plot 'number of priciple components' against 'Explained variance'.\n",
    "#It is needed only when you need to visuallize intermediate PCA result.\n",
    "#The code need to be put at proper place before execution.\n",
    "    #print(\"Variance explained by all 512 principal components =\", sum(pca_512.explained_variance_ratio_ * 100))\n",
    "    #plt.plot(np.cumsum(pca_512.explained_variance_ratio_ * 100))\n",
    "    #plt.xlabel('number of priciple components')\n",
    "    #plt.ylabel('Explained variance')\n",
    "    #plt.savefig('BrainTumorPCA512.png',dpi = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa2d797",
   "metadata": {},
   "source": [
    "Reduce dimension for 3000 images from 512-512 to 512-102 dimension; After dimension recution, read into \"imgs\" array; each reduced image is flattened into one row and also reduced from RGB to grey scale; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7561773f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "imgs = np.zeros((rows,512*pca_num.astype(np.int64)))          #Initialize an array for all reduced images\n",
    "\n",
    "for i in range(rows):                \n",
    "    img = mpimg.imread(dir_image + csv_array.file_name[i])[...,0]\n",
    "    \n",
    "    pca_102 = PCA(n_components = 102, random_state = 2020) \n",
    "    pca_102.fit(img)\n",
    "    imgs_pca_102 = pca_102.transform(img)\n",
    "    \n",
    "    imgs[i] = imgs_pca_102.flatten()\n",
    "    if i%500 == 0:     #print index to indicate processing progress\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e34fab",
   "metadata": {},
   "source": [
    "Modify csv_array.label to adapt to binary clasification (only \"no_tumor\" and \"has_tumor\" are valid labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24fbb357",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(rows):\n",
    "    if csv_array.label[i] != \"no_tumor\" :\n",
    "        csv_array.label[i] = \"has_tumor\" #only no_tumor and has_tumor are valid labels for binary clasifcation task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe77af7",
   "metadata": {},
   "source": [
    "Split train/test data set by 9:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fada3ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(imgs, csv_array.label[0:rows], test_size=0.10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8baab",
   "metadata": {},
   "source": [
    "Tune hyperparameter C, kernek and gamma for SVM model to get better classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54e884e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8726666666666666\n",
      "Best Hyperparameters: {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 5, 10, 20, 40], 'kernel': ['rbf']},\n",
    "  {'C': [1, 5, 10, 20, 40], 'kernel': ['linear']},\n",
    " ]\n",
    "svc = SVC()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "clf = GridSearchCV(svc, param_grid=param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "result = clf.fit(x_train[0:500], y_train[0:500])\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04b28a0",
   "metadata": {},
   "source": [
    "Use tuned parameters to build new model;\n",
    "Train model and predict on test data set;\n",
    "Print accuracy score;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b087c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_tuned = SVC(kernel='rbf', C=10)\n",
    "svc_tuned.fit(x_train, y_train)\n",
    "y_pred = svc_tuned.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceece83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "##\n",
    "## This part is not used. It is another way to tune hyperparameter (RandomizedSearchCV)\n",
    "##\n",
    "#######################################################################################\n",
    "\n",
    "#param_distributions = {\"C\": uniform(1, 10)} #Random tune C between 1 and 100\n",
    "#model = SVC(kernel='rbf', gamma='scale')\n",
    "#clf = RandomizedSearchCV(model,param_distributions, n_iter=10, random_state=0)\n",
    "#search = clf.fit(x_train[0:300], y_train[0:300]) \n",
    "#search.best_estimator_   #SVC(C=5.236547993389047)\n",
    "\n",
    "##Train SVM model (best_estimator_) and predict based on test data set. Print accuracy score.\n",
    "\n",
    "#search.best_estimator_.fit(x_train, y_train)\n",
    "#y_pred = search.best_estimator_.predict(x_test)\n",
    "#accuracy_score(y_test, y_pred) #0.9333333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a7918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
